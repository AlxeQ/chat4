import os
import pandas as pd
import docx2txt
import tempfile
import pdfplumber
import requests
import streamlit as st
from io import BytesIO

# ä»ç¯å¢ƒå˜é‡è¯»å–DeepSeek API Key
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")

def call_deepseek_api(prompt):
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }
    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        return f"è°ƒç”¨ DeepSeek API å¤±è´¥ï¼ŒçŠ¶æ€ç  {response.status_code}: {response.text}"

def extract_text_from_pdf(uploaded_file):
    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def extract_text_from_docx(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(uploaded_file.read())
        tmp.flush()
        text = docx2txt.process(tmp.name)
    return text

def extract_text(file):
    if file.name.endswith(".pdf"):
        return extract_text_from_pdf(file)
    elif file.name.endswith(".docx"):
        return extract_text_from_docx(file)
    elif file.name.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"

def analyze_interview(transcript, outline, target):
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¿è°ˆå†…å®¹ç»“æ„åŒ–è®°å½•ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©å›¢é˜Ÿ**å®Œæ•´è¿˜åŸå—è®¿è€…è®²è¿°çš„æ¯ä¸ªè§‚ç‚¹ã€å®Œæ•´æ¡ˆä¾‹ä¸ç»†èŠ‚**ï¼Œå¹¶å°†å…¶ä¸è®¿è°ˆå¤§çº²é€ä¸€æ¯”å¯¹ã€åˆ†ç±»å½’æ¡£ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å®Œæˆä»»åŠ¡ï¼š

---

**ä¸€ã€å¤§çº²é€æ¡æ¯”å¯¹ï¼ˆå¿…é¡»é€æ¡è¾“å‡ºï¼‰**
- è¯·ä¸¥æ ¼æŒ‰ç…§è®¿è°ˆå¤§çº²ä¸­çš„æ¯ä¸€é¡¹ï¼Œé€ä¸€åˆ¤æ–­è®¿è°ˆä¸­æ˜¯å¦æœ‰æ˜ç¡®å›åº”ã€‚
- è‹¥æœ‰å›åº”ï¼Œè¯·å°½å¯èƒ½å®Œæ•´æå–å…¸å‹è¯´æ³•ã€å…³é”®æ•°æ®ä¸å…·ä½“ç»†èŠ‚ï¼Œä¿ç•™ä»£è¡¨æ€§åŸè¯ã€‚
- è‹¥ä¸ºâ€œéƒ¨åˆ†è¦†ç›–â€æˆ–â€œæœªè¦†ç›–â€ï¼Œè¯·å¡«å†™**ç²¾å‡†å¯æ“ä½œçš„è¡¥é—®å»ºè®®**ã€‚

**äºŒã€æ¡ˆä¾‹ä¸çº¿ç´¢æŠ½å–**
- è¯·æå–è®¿è°ˆä¸­æ‰€æœ‰åŒ…å«**æ—¶é—´ã€äººç‰©ã€äº‹ä»¶ã€ç»“æœ**çš„ä¿¡æ¯ï¼Œè¯†åˆ«ä¸ºâ€œæ¡ˆä¾‹è¡¥å……â€æˆ–â€œæ•°æ®çº¿ç´¢â€ã€‚
- ä¸è®ºæ˜¯å¦åœ¨å¤§çº²ä¸­å‡ºç°ï¼Œå‡åº”çº³å…¥è¡¨æ ¼ç»Ÿä¸€æ•´ç†ã€‚

---

**ä¸‰ã€è¾“å‡ºæ ¼å¼ï¼ˆMarkdownè¡¨æ ¼ï¼Œå¿…é¡»ä»è¡¨å¤´å¼€å§‹ï¼‰**
è¯·ç”Ÿæˆå¦‚ä¸‹æ ¼å¼çš„è¡¨æ ¼ï¼Œå†…å®¹è¯¦å®ï¼Œç»“æ„æ¸…æ™°ï¼š

| ç±»å‹ | é—®é¢˜æˆ–ä¸»é¢˜ | å†…å®¹æ‘˜è¦ | åŸå§‹è¯æœ¯ | è¦†ç›–æƒ…å†µ | è¡¥é—®å»ºè®® |
|------|------------|----------|-----------|-----------|-----------|

- ç±»å‹åŒ…å«ï¼šå¤§çº²å¯¹åº” / æ¡ˆä¾‹è¡¥å…… / æ•°æ®çº¿ç´¢
- å†…å®¹æ‘˜è¦ä¸å°‘äº50å­—ï¼Œçªå‡ºé‡ç‚¹ï¼Œé¿å…å‹ç¼©è¿‡åº¦
- åŸå§‹è¯æœ¯è¯·èŠ‚é€‰å—è®¿è€…è¡¨è¿°åŸå¥
- â€œè¦†ç›–æƒ…å†µâ€è¯·ä¸¥æ ¼ä½¿ç”¨ï¼šæ˜¯ / å¦ / éƒ¨åˆ†è¦†ç›–
- è‹¥ä¸ºâ€œå¦â€æˆ–â€œéƒ¨åˆ†è¦†ç›–â€ï¼Œ**è¡¥é—®å»ºè®®ä¸ºå¿…å¡«é¡¹**
- è¯·ä»…è¾“å‡ºè¡¨æ ¼å†…å®¹ï¼Œä»è¡¨å¤´å¼€å§‹ï¼Œè¯·å‹¿æ·»åŠ è§£é‡Šæ€§æ–‡å­—

---

**å¯é€‰è¾“å‡ºï¼ˆå¦‚æœ‰å¼€å¯ï¼‰**
è‹¥å…è®¸è¡¥å……ï¼Œè¯·åœ¨è¡¨æ ¼ä¹‹åè¿½åŠ ï¼š

ã€æ€»ç»“ã€‘æ¦‚æ‹¬æœ¬æ¬¡è®¿è°ˆä¸­çš„å…³é”®å‘ç°ï¼ˆä¸è¶…è¿‡200å­—ï¼‰  
ã€å»ºè®®ã€‘åˆ—å‡º3æ¡åŸºäºå†…å®¹çš„å¯èƒ½è¡¥é—®æˆ–ä¼˜åŒ–æ–¹å‘

---
ã€è®¿è°ˆç›®æ ‡ã€‘
{target}

ã€è®¿è°ˆå¤§çº²ã€‘
{outline}

ã€è®¿è°ˆåŸæ–‡ã€‘
{transcript}
"""
    return call_deepseek_api(prompt)

def main():
    st.set_page_config(page_title="è®¿è°ˆç»“æ„æ•´ç†å·¥å…·", layout="wide")
    st.title("ğŸ“‹ è®¿è°ˆç»“æ„æ•´ç† MVP å·¥å…·")

    target = st.text_area("è¯·è¾“å…¥è®¿è°ˆç›®æ ‡ï¼ˆä¾‹å¦‚ï¼šæœ¬æ¬¡è®¿è°ˆä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆï¼‰")

    st.markdown("### ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ è®¿è°ˆæ–‡ä»¶ï¼ˆpdfã€docxã€txtï¼‰")
    interview_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆè®°å½•æ–‡ä»¶ï¼š", type=["pdf", "docx", "txt"])

    st.markdown("### ç¬¬äºŒæ­¥ï¼šä¸Šä¼ è®¿è°ˆå¤§çº²ï¼ˆdocxã€txtï¼‰")
    outline_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆå¤§çº²æ–‡ä»¶ï¼š", type=["docx", "txt"])

    edited_result = ""

    if st.button("ğŸš€ å¼€å§‹åˆ†æ") and interview_file and outline_file and target.strip() != "":
        with st.spinner("â³ æ­£åœ¨æå–ä¸åˆ†æå†…å®¹ï¼Œè¯·ç¨å€™..."):
            transcript = extract_text(interview_file)
            outline = extract_text(outline_file)

            result_markdown = analyze_interview(transcript, outline, target)

        st.markdown("### âœ… åˆ†æç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰")
        edited_result = st.text_area("ä½ å¯ä»¥åœ¨æ­¤ä¿®æ”¹ç”Ÿæˆçš„å†…å®¹ï¼š", result_markdown, height=600)

        try:
            df_list = pd.read_html(edited_result, flavor="bs4")
            if df_list:
                df = df_list[0]
                output = BytesIO()
                df.to_excel(output, index=False, engine='openpyxl')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»“æœä¸º Excel",
                    data=output.getvalue(),
                    file_name="interview_analysis.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("âš ï¸ æœªèƒ½è¯†åˆ«è¡¨æ ¼æ•°æ®ï¼Œè¯·æ£€æŸ¥ä¿®æ”¹åçš„å†…å®¹æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        except Exception as e:
            st.error(f"âŒ è½¬æ¢ç»“æœå¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    main()
