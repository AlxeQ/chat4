import os
import pandas as pd
import docx2txt
import tempfile
import pdfplumber
import requests
import streamlit as st
from io import BytesIO

# ä»ç¯å¢ƒå˜é‡è¯»å–DeepSeek API Key
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")

def call_deepseek_api(prompt):
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }
    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        return f"è°ƒç”¨ DeepSeek API å¤±è´¥ï¼ŒçŠ¶æ€ç  {response.status_code}: {response.text}"

def extract_text_from_pdf(uploaded_file):
    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def extract_text_from_docx(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(uploaded_file.read())
        tmp.flush()
        text = docx2txt.process(tmp.name)
    return text

def extract_text(file):
    if file.name.endswith(".pdf"):
        return extract_text_from_pdf(file)
    elif file.name.endswith(".docx"):
        return extract_text_from_docx(file)
    elif file.name.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"

def analyze_interview(transcript, outline, target):
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¿è°ˆå†…å®¹ç»“æ„åŒ–è®°å½•ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©å›¢é˜Ÿ**å®Œæ•´è¿˜åŸå—è®¿è€…è®²è¿°çš„æ¯ä¸ªè§‚ç‚¹ã€å®Œæ•´æ¡ˆä¾‹ä¸ç»†èŠ‚**ï¼Œå¹¶å°†å…¶ä¸è®¿è°ˆå¤§çº²é€ä¸€æ¯”å¯¹ã€åˆ†ç±»å½’æ¡£ã€‚

**ä¸€ã€å¤§çº²é€æ¡æ¯”å¯¹**
- è¯·éå†ä»¥ä¸‹è®¿è°ˆå¤§çº²ä¸­çš„æ¯ä¸ªé—®é¢˜ï¼Œåˆ¤æ–­è®¿è°ˆä¸­æ˜¯å¦è¿›è¡Œäº†å›ç­”ã€‚
- è‹¥æœ‰å›ç­”ï¼Œè¯·å®Œæ•´æå–å¯¹åº”å†…å®¹ï¼Œä¿ç•™å…¸å‹è¯´æ³•ã€å…³é”®æ•°æ®ã€å…·ä½“ç»†èŠ‚ã€‚
- è‹¥æ— æ˜ç¡®å›ç­”ï¼Œè¯·æå‡ºå¯ç›´æ¥ç”¨äºè¡¥å……è®¿è°ˆçš„å…·ä½“è¡¥é—®å»ºè®®ã€‚

**äºŒã€æ¡ˆä¾‹ä¸çº¿ç´¢æŠ½å–**
- è¯†åˆ«è®¿è°ˆä¸­æ‰€æœ‰åŒ…å«æ—¶é—´ã€äººç‰©ã€äº‹ä»¶ã€ç»“æœçš„å®Œæ•´æ¡ˆä¾‹ä¸ç»éªŒåˆ†äº«ã€‚
- æå–å…¶ä¸­çš„å…³é”®æ•…äº‹ã€æˆè´¥ç»éªŒã€é‡åŒ–æ•°æ®ã€å¯è¿½é—®çš„çº¿ç´¢ã€‚

**ä¸‰ã€è¾“å‡ºæ ¼å¼ï¼ˆMarkdownè¡¨æ ¼ï¼‰**
è¯·ç”Ÿæˆå¦‚ä¸‹æ ¼å¼çš„è¡¨æ ¼ï¼ˆä¸é™äºå¤§çº²é—®é¢˜ï¼‰ï¼š

| ç±»å‹ | é—®é¢˜æˆ–ä¸»é¢˜ | å†…å®¹æ‘˜è¦ | åŸå§‹è¯æœ¯ | è¦†ç›–æƒ…å†µ | è¡¥é—®å»ºè®® |
|------|------------|----------|-----------|-----------|-----------|
- ç±»å‹åŒ…å«ï¼šå¤§çº²å¯¹åº” / æ¡ˆä¾‹è¡¥å…… / æ•°æ®çº¿ç´¢
- è¦†ç›–æƒ…å†µè¯·å¡«å†™â€œæ˜¯/å¦/éƒ¨åˆ†è¦†ç›–â€
- å†…å®¹æ‘˜è¦ä¸å°‘äº50å­—ï¼Œé¿å…å‹ç¼©è¿‡åº¦
- åŸå§‹è¯æœ¯è¯·èŠ‚é€‰å—è®¿è€…çš„åŸå¥
- å¦‚æœ‰é—æ¼ï¼Œè¯·å¡«å†™å…·ä½“è¡¥é—®å»ºè®®ï¼Œé—®é¢˜ç²¾å‡†å¯æ“ä½œ

---

ã€è®¿è°ˆç›®æ ‡ã€‘
{target}

ã€è®¿è°ˆå¤§çº²ã€‘
{outline}

ã€è®¿è°ˆåŸæ–‡ã€‘
{transcript}
"""
    return call_deepseek_api(prompt)

def main():
    st.set_page_config(page_title="è®¿è°ˆç»“æ„æ•´ç†å·¥å…·", layout="wide")
    st.title("ğŸ“‹ è®¿è°ˆç»“æ„æ•´ç† MVP å·¥å…·")

    target = st.text_area("è¯·è¾“å…¥è®¿è°ˆç›®æ ‡ï¼ˆä¾‹å¦‚ï¼šæœ¬æ¬¡è®¿è°ˆä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆï¼‰")

    st.markdown("### ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ è®¿è°ˆæ–‡ä»¶ï¼ˆpdfã€docxã€txtï¼‰")
    interview_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆè®°å½•æ–‡ä»¶ï¼š", type=["pdf", "docx", "txt"])

    st.markdown("### ç¬¬äºŒæ­¥ï¼šä¸Šä¼ è®¿è°ˆå¤§çº²ï¼ˆdocxã€txtï¼‰")
    outline_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆå¤§çº²æ–‡ä»¶ï¼š", type=["docx", "txt"])

    edited_result = ""

    if st.button("ğŸš€ å¼€å§‹åˆ†æ") and interview_file and outline_file and target.strip() != "":
        with st.spinner("â³ æ­£åœ¨æå–ä¸åˆ†æå†…å®¹ï¼Œè¯·ç¨å€™..."):
            transcript = extract_text(interview_file)
            outline = extract_text(outline_file)

            result_markdown = analyze_interview(transcript, outline, target)

        st.markdown("### âœ… åˆ†æç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰")
        edited_result = st.text_area("ä½ å¯ä»¥åœ¨æ­¤ä¿®æ”¹ç”Ÿæˆçš„å†…å®¹ï¼š", result_markdown, height=600)

        try:
            df_list = pd.read_html(edited_result, flavor="bs4")
            if df_list:
                df = df_list[0]
                output = BytesIO()
                df.to_excel(output, index=False, engine='openpyxl')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»“æœä¸º Excel",
                    data=output.getvalue(),
                    file_name="interview_analysis.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("âš ï¸ æœªèƒ½è¯†åˆ«è¡¨æ ¼æ•°æ®ï¼Œè¯·æ£€æŸ¥ä¿®æ”¹åçš„å†…å®¹æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        except Exception as e:
            st.error(f"âŒ è½¬æ¢ç»“æœå¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    main()
